{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d66ee8-0c65-4fef-b7b9-e11a627a0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "!!!!!!!!!!!!!!!!!!!!! 'https://www.accordbox.com/blog/how-crawl-infinite-scrolling-pages-using-python/' !!!!!!!!!!!!!!!!!!!!!!!\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b7beab6-75f0-4d02-854d-00532da74e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------------------------- importer les librairies nécessaires-------------------------------------------------\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ada1acf-fc79-4bf3-9525-72e6e978ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez le produit recheché:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " iPhone 12 pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [/Users/tam/.wdm/drivers/chromedriver/mac64/102.0.5005.61/chromedriver] found in cache\n",
      "/var/folders/m2/fdycypmn5fs5tzy134bmr9dm0000gn/T/ipykernel_19432/4280982213.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n",
      "/var/folders/m2/fdycypmn5fs5tzy134bmr9dm0000gn/T/ipykernel_19432/4280982213.py:33: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  elems = driver.find_elements_by_xpath(\"//a[@href]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# -------------------------------------- récupère les liens de chaque page produit --------------------------------------------\n",
    "\n",
    "url = []\n",
    "\n",
    "\n",
    "# le client entre la 2e page du produit recherché, pour qu'on puisse en déduire la 'base url'\n",
    "print(\"Entrez le produit recheché:\")\n",
    "produit = input().split(' ')        \n",
    "\n",
    "# Base de l'Url, on le construit à partir du produit (puis par la suite on ajoute le numéro de chaque page)\n",
    "# si on entre 'iphone 12 pro'                                  --->   cela nous donne:\n",
    "# https://fr.aliexpress.com/af/iPhone-12-pro.html?trafficChannel=af&d=y&CatId=0&SearchText=iPhone+12+pro&ltype=affiliate&SortType=default&page=4\n",
    "base_url = ''.join(['https://fr.aliexpress.com/af/', ''.join(['-' + produit[i] for i in range(1,len(produit)) if len(produit) > 1]),\n",
    "                    '.html?trafficChannel=af&d=y&CatId=0&SearchText=',\n",
    "                    ''.join(['+' + produit[i] for i in range(1,len(produit)) if len(produit) > 1]), '&ltype=affiliate&SortType=default&page={}']) \n",
    "\n",
    "# ouvrir le navigateur Chrome, et aller sur la 1ere page qu'on a quand on recherche un produit\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "try:              # au cas où il y a moins de 100 pages\n",
    "    for i in range(1,101):  # sur 100 pages max\n",
    "\n",
    "        # aller à l'url de chaque page disponible: page1, page2, ect \n",
    "        driver.get(base_url.format(i))\n",
    "\n",
    "        # scroller tout en bas pour bien faire apparaitre tous les éléments de la page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(randint(3,5))\n",
    "\n",
    "        # récupérer tous les liens de la page                \n",
    "        elems = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "        for elem in elems:\n",
    "            # ajouter seulement ceux qui permettent d'accéder au fiches produits (/'item')\n",
    "            if 'https://fr.aliexpress.com/item/' in str(elem.get_attribute(\"href\")):\n",
    "                url.append(str(elem.get_attribute(\"href\")))\n",
    "                \n",
    "        # enlever les liens en doublons\n",
    "        url = list(set(url))\n",
    "        \n",
    "        \n",
    "        time.sleep(randint(5,12))\n",
    "except:pass\n",
    "\n",
    "    \n",
    "#print(url)\n",
    "print(len(url))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb503f34-53e2-49b5-a9fc-5d3b5aae57f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Produit</th>\n",
       "      <th>Prix (€)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo Vengeurs Anime Pour iPhone 11 13 Pro Max...</td>\n",
       "      <td>1.9€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coque de téléphone en TPU souple coloré, motif...</td>\n",
       "      <td>24.14€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Étui portefeuille à rabat en cuir PU avec fent...</td>\n",
       "      <td>2.45€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GYKZ – coque de téléphone transparente en TPU ...</td>\n",
       "      <td>1.61€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magsafing – coque rigide et transparente pour ...</td>\n",
       "      <td>12.03€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Marilyn Monroe – coque souple transparente pou...</td>\n",
       "      <td>3.43€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Rappeur Brent Faiyaz pour iPhone 11 12 13 Pro ...</td>\n",
       "      <td>2.72€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Coque de téléphone portable avec bracelet de p...</td>\n",
       "      <td>26.16€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Coque de téléphone Apple à motif de poisson, é...</td>\n",
       "      <td>1.7€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2022 Dragon noir Pour iPhone 11 7 8 Plus X XR ...</td>\n",
       "      <td>14.36€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Produit Prix (€)\n",
       "0    Tokyo Vengeurs Anime Pour iPhone 11 13 Pro Max...     1.9€\n",
       "1    Coque de téléphone en TPU souple coloré, motif...   24.14€\n",
       "2    Étui portefeuille à rabat en cuir PU avec fent...    2.45€\n",
       "3    GYKZ – coque de téléphone transparente en TPU ...    1.61€\n",
       "4    Magsafing – coque rigide et transparente pour ...   12.03€\n",
       "..                                                 ...      ...\n",
       "755  Marilyn Monroe – coque souple transparente pou...    3.43€\n",
       "756  Rappeur Brent Faiyaz pour iPhone 11 12 13 Pro ...    2.72€\n",
       "757  Coque de téléphone portable avec bracelet de p...   26.16€\n",
       "758  Coque de téléphone Apple à motif de poisson, é...     1.7€\n",
       "759  2022 Dragon noir Pour iPhone 11 7 8 Plus X XR ...   14.36€\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------------------------- récupère infos sur chaque page produit ---------------------------------------------\n",
    "\n",
    "Prix = []\n",
    "Nom = []\n",
    "\n",
    "\n",
    "for i in url:\n",
    "    # recupère html de chaque page                \n",
    "    r = requests.get(i)  \n",
    "        # Convertit en chaine de caractères puis en objet BS\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "    # récupère le titre (qui contient le prix), supprime le début '<meta content=' pour garder que le 1er élément (le prix) de la liste (de split)\n",
    "    Prix.append(str(soup.find(\"meta\", property=\"og:title\")).replace('<meta content=\"', '').split(' ')[0])\n",
    "    Nom.append(soup.find('title').text.replace('| AliExpress','')) # prends le titre du produit (et enlève la fin inutile)\n",
    "\n",
    "\n",
    "# tableau des données        \n",
    "tableau = pd.DataFrame(list(zip(Nom,Prix)), columns = ['Produit','Prix (€)'])\n",
    "\n",
    "# transférer les données dans un fichier CSV\n",
    "tableau.to_csv(''.join(produit)+'-AliExpress_fichePrix.csv')\n",
    "tableau     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf90c8-ada5-4219-8c76-7f022e99757f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7536ab-5eb0-4f72-9b72-b78de80d6ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071be2e-fd92-4269-be72-05e631b25b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246191be-b5c9-4fbe-80b2-2d2b4bb16e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d731f8-e398-4835-806c-c8daa4bcce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a4cb7-5cab-4d9f-af5b-465da872c410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405c24d-f67d-46dd-85e8-433bb2f1c738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97be8e-f696-4c91-b096-67da24bf1904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3226fff1-0ca9-4dde-9735-2628d490c96a",
   "metadata": {},
   "source": [
    "\n",
    "#### **------------------------------------------------------  Recherches  ----------------------------------------------------------**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2677f5-1dff-4eda-a349-d1e69cf08425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                       # pour aller chercher l'url\n",
    "from bs4 import BeautifulSoup         # pour découper le html \n",
    "import time                           \n",
    "import pandas as pd                   # pour classer les données dans un tableau\n",
    "import csv\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import re                             # regex\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# le client entre la 2e page du produit recherché, pour qu'on puisse en déduire la 'base url'\n",
    "print(\"Entrez le produit recheché:\")\n",
    "produit = input().split(' ')        \n",
    "\n",
    "# Base de l'Url, on le construit à partir du produit (puis par la suite on ajoute le numéro de chaque page)\n",
    "# si on entre 'table basse ronde'                                  --->   cela nous donne 'https://www.amazon.fr/s?k=table+basse+ronde&page='  \n",
    "base_url = ''.join(['https://www.alibaba.com/trade/search?spm=a2700.galleryofferlist.0.0.3bf24ec1NDaDf8&IndexArea=product_en&SearchText=',\n",
    "                    produit[0], ''.join(['_' + produit[i] for i in range(1,len(produit)) if len(produit) > 1]), '&page={}'])    #{}\n",
    "\n",
    "# listes contenant le Noms des produits et leurs Prix\n",
    "Prix = []\n",
    "Noms_Produits = []\n",
    "Vendeurs = []\n",
    "\n",
    "\n",
    "while True: \n",
    "    \n",
    "    # boucle pour assurer la rotation des pages: on incrémente le nombre dans l'url: 'page1', 'page2'...\n",
    "    for i in range(1,101):\n",
    "\n",
    "        # recupère html de chaque page                \n",
    "        r = requests.get(base_url.format(i))  # page=1, page =2... \n",
    "        # Convertit en chaine de caractères puis en objet BS\n",
    "        contentPage = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "        for bloc in contentPage.findAll('div', {'class':'list-no-v2-inner m-gallery-product-item-v2 img-switcher-parent'}):\n",
    "\n",
    "            #1) - récupère les noms de chaque produit, et les ajoute à la liste 'Noms_Produits' \n",
    "            if bloc.find('p', {'class':'elements-title-normal__content large'}): \n",
    "                Noms_Produits.append(bloc.find('p', {'class':'elements-title-normal__content large'}).getText())\n",
    "            else:Noms_Produits.append('none')\n",
    "\n",
    "\n",
    "            #2) - récupère les prix, et les ajoute à la liste 'Prix'     ---> s'il n y a pas de prix parce que tout vendu, alors on ajoute 'vendus'   \n",
    "            if bloc.find('span', {'class':'elements-offer-price-normal__promotion'}): \n",
    "                Prix.append(bloc.find('span', {'class':'elements-offer-price-normal__promotion'}).getText())\n",
    "            else:Prix.append('none')\n",
    "\n",
    "            sleep(randint(1,4))\n",
    "\n",
    "            #3) - récupère le vendeur, et l'ajoute à la liste 'Vendeurs' (! ---> récupère ça sur la page qu'on a quand on clique sur le produit)                       \n",
    "            try: \n",
    "                lien_vendeurProduit = bloc.find('a',\n",
    "                        {'class':'elements-title-normal one-line'}, href=True)['href']\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "                r = requests.get('https:' + lien_vendeurProduit)  # page=1, page =2...\n",
    "                # Convertit en chaine de caractères puis en objet BS\n",
    "                contentPageVendeur = BeautifulSoup(r.content, 'lxml')   \n",
    "                if 'Toutes nos excuses' in contentPageVendeur.getText()[:21]: print(contentPageVendeur.getText()[:20], '3')\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------#            \n",
    "    #             # récupérer le nom du vendeur\n",
    "    #             Vendeurs.append(contentPageVendeur.find('a', {'id':'bylineInfo'}).getText().replace('Visiter la boutique ', ''))\n",
    "            except:pass\n",
    "    #               Vendeurs.append('none')\n",
    "    #         sleep(randint(2,5))\n",
    "\n",
    "\n",
    "\n",
    "        sleep(15)\n",
    "        print('Page: '+ str(i) + '/' + '100 or less' + ', fait')        \n",
    "\n",
    "\n",
    "\n",
    "print(base_url)\n",
    "# tableau des données        \n",
    "tableau = pd.DataFrame(list(zip(Noms_Produits,Prix, Vendeurs)), columns = ['produit','prix (€)', 'vendeur'])\n",
    "\n",
    "# transférer les données dans un fichier CSV\n",
    "tableau.to_csv(''.join(produit)+'-Aliexpress_fichePrix.csv')\n",
    "tableau      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db7203-15ce-4acf-87f3-f766b90617c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eae545-bcb5-4706-a685-03c10b18d669",
   "metadata": {},
   "source": [
    "#                    -          autre méthode qui peut être utile (si besoin de plus d'infos)           -                     #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f67f1a-676f-472e-9856-2f7668771fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca2295-6910-4e45-ae88-2acbf581f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------------------------- récupère infos sur chaque page produit ---------------------------------------------\n",
    "\n",
    "from requests_html import AsyncHTMLSession\n",
    "import pyppdf.patch_pyppeteer\n",
    "\n",
    "\n",
    "Product_name = []\n",
    "Rating = []\n",
    "Review_count = []\n",
    "Price = []\n",
    "\n",
    "\n",
    "\n",
    "# set headers\n",
    "header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36'}\n",
    "\n",
    "\n",
    "for lien in url:\n",
    "    try:\n",
    "        # Start html session and send get request:\n",
    "        asession = AsyncHTMLSession()\n",
    "        r = await asession.get(lien)\n",
    "\n",
    "        # Render Java Script:\n",
    "        await r.html.arender()\n",
    "\n",
    "\n",
    "        # Get product name:\n",
    "        h1 = r.html.find('h1')\n",
    "        ' '.join(h1[0].text.split(' ')[:10])\n",
    "        Product_name.append(h1)\n",
    "\n",
    "        # Product Rating:\n",
    "        rating = r.html.find('.overview-rating-average')\n",
    "        ''.join(rating[0].text.split(' ')[0])\n",
    "        Rating.append(rating)\n",
    "\n",
    "        # Review Count:\n",
    "        rating_count = r.html.find('.product-reviewer-reviews')\n",
    "        ''.join(rating_count[0].text.split(' ')[0])\n",
    "        Review_count.append(rating_count)\n",
    "\n",
    "        # Product price:\n",
    "        price = r.html.find('.product-price-value')\n",
    "        ''.join(price[0].text.split(' ')[0:2])\n",
    "        Price.append(price)\n",
    "    except:pass\n",
    "    \n",
    "    # afficher la progression\n",
    "    \n",
    "\n",
    "\n",
    "# tableau des données        \n",
    "tableau = pd.DataFrame(list(zip(Product_name,Rating,Review_count,Price)), columns = ['Produit', 'Note', \"Nombre d'avis\", 'Prix (€)'])\n",
    "\n",
    "# transférer les données dans un fichier CSV\n",
    "tableau.to_csv(''.join(produit)+'-AliExpress_fichePrix.csv')\n",
    "tableau   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
